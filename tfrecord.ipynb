{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Write TFRecord\n",
    "\n",
    "> Krishna Kumar and Joseph Vantassel, The University of Texas at Austin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and this file should be outside learning_to_simulate code folder\n",
    "import functools\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "from learning_to_simulate import reading_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set datapath and validation set\n",
    "data_path = './datasets/WaterRamps'\n",
    "filename = 'valid.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata\n",
    "def _read_metadata(data_path):\n",
    "    with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
    "        return json.loads(fp.read())\n",
    "\n",
    "# Fetch metadata\n",
    "metadata = _read_metadata(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': [[0.1, 0.9], [0.1, 0.9]], 'sequence_length': 600, 'default_connectivity_radius': 0.015, 'dim': 2, 'dt': 0.0025, 'vel_mean': [-6.141567458658365e-08, -0.0007425391691160353], 'vel_std': [0.0022381126134429557, 0.0022664486850394443], 'acc_mean': [-1.713503820317499e-07, -2.1448168008479274e-07], 'acc_std': [0.00016824548701156486, 0.0001819676291787043]}\n"
     ]
    }
   ],
   "source": [
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read All Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  {'particle_type': <tf.Tensor 'Reshape_1:0' shape=(None,) dtype=int64>, 'key': <tf.Tensor 'ParseSingleSequenceExample/ParseSequenceExample/ParseSequenceExampleV2:3' shape=() dtype=int64>}\n",
      "features:  {'position': <tf.Tensor 'Reshape:0' shape=(601, None, 2) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "ds_org = tf.data.TFRecordDataset([os.path.join(data_path, filename)])\n",
    "ds = ds_org.map(functools.partial(reading_utils.parse_serialized_simulation_example, metadata=metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Single Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dataset = tf.data.TFRecordDataset(\"datasets/WaterRamps/valid.tfrecord\")\n",
    "\n",
    "# for raw_record in raw_dataset.take(1):\n",
    "#     example = tf.train.SequenceExample()\n",
    "#     example.ParseFromString(raw_record.numpy())\n",
    "# a_true, b_true = example.ListFields()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lds = list(ds)\n",
    "\n",
    "particle_types = []\n",
    "keys = []\n",
    "positions = []\n",
    "for _ds in ds:\n",
    "    context, features = _ds\n",
    "    particle_types.append(context[\"particle_type\"].numpy().astype(np.int64))\n",
    "    keys.append(context[\"key\"].numpy().astype(np.int64))\n",
    "    positions.append(features[\"position\"].numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write New TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.python_io.TFRecordWriter('test.tfrecord') as writer:\n",
    "    \n",
    "    for step, (particle_type, key, position) in enumerate(zip(particle_types, keys, positions)):\n",
    "        seq = tf.train.SequenceExample(\n",
    "                context=tf.train.Features(feature={\n",
    "                    \"particle_type\": _bytes_feature(particle_type.tobytes()),\n",
    "                    \"key\": _int64_feature(key)\n",
    "                }),\n",
    "                feature_lists=tf.train.FeatureLists(feature_list={\n",
    "                    'position': tf.train.FeatureList(\n",
    "                        feature=[_bytes_feature(position.flatten().tobytes())],\n",
    "                    ),\n",
    "                    'step_context': tf.train.FeatureList(\n",
    "                        feature=[_bytes_feature(np.float32(step).tobytes())]\n",
    "                    ),\n",
    "                })\n",
    "            )\n",
    "\n",
    "        writer.write(seq.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read New TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  {'particle_type': <tf.Tensor 'Reshape_1:0' shape=(None,) dtype=int64>, 'key': <tf.Tensor 'ParseSingleSequenceExample/ParseSequenceExample/ParseSequenceExampleV2:3' shape=() dtype=int64>}\n",
      "features:  {'position': <tf.Tensor 'Reshape:0' shape=(601, None, 2) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "dt = tf.data.TFRecordDataset(['test.tfrecord'])\n",
    "dt = dt.map(functools.partial(reading_utils.parse_serialized_simulation_example, metadata=metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Original and New TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecords are similar!\n"
     ]
    }
   ],
   "source": [
    "for ((_ds_context, _ds_feature), (_dt_context, _dt_feature)) in zip(ds, dt):\n",
    "    if not np.allclose(_ds_context[\"key\"].numpy(), _dt_context[\"key\"].numpy()):\n",
    "        break\n",
    "\n",
    "    if not np.allclose(_ds_context[\"particle_type\"].numpy(), _dt_context[\"particle_type\"].numpy()):\n",
    "        break\n",
    "    \n",
    "    if not np.allclose(_ds_feature[\"position\"].numpy(), _dt_feature[\"position\"].numpy()):\n",
    "        break\n",
    "\n",
    "else:\n",
    "    print(\"TFRecords are similar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
